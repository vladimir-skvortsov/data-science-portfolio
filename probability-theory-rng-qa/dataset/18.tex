\subsection{Условное математическое ожидание в дискретном случае относительно разбиения и относительно случайной величины. Основные свойства: линейность, монотонность, формула полной вероятности, условное ожидание величины, независимой с разбиением, вынесение случайной величины из под знака условного ожидания. Эквивалентное определение условного математического ожидания и геометрическая интерпретация.}

\subsubsection{Условное математическое ожидание в дискретном случае относительно разбиения и относительно случайной величины.}
\begin{definition}
	Величину $\Lambda$ называют условным математическим ожиданием $X$ относительно разбиения $\boldsymbol{\beta}$ и обозначают через $\mathbb{E}(X|\boldsymbol{\beta})$.
\end{definition}

\begin{definition}
Рассмотрим случай, когда разбиение $\boldsymbol{\beta}$ появляется посредством некоторой случайной величины $Y = \sum_{k=1}^{n}y_kI_{B_k}$, где $y_k$ - различные числа и $P(B_k) > 0$. В этом случае $B_k = \{\omega : Y (\omega) = y_k\}$ и условное математическое ожидание $\mathbb{E}(X|\boldsymbol{\beta})$ обозначают символом $\mathbb{E}(X|Y)$ и называют условным математическим ожиданием случайной величины X относительно случайной величины Y.
\end{definition}

\subsubsection{Основные свойства: линейность, монотонность, формула полной вероятности, условное ожидание величины, независимой с разбиением, вынесение случайной величины из под знака условного ожидания.}
\begin{theorem}
	Имеют место следующие свойства условного математического ожидания:
	
	(i) (линейность) $\mathbb{E}(\alpha X + \beta Y |\boldsymbol{\beta}) = \alpha\mathbb{E}(X|\boldsymbol{\beta}) + \beta\mathbb{E}(Y |\boldsymbol{\beta})$,
	
	(ii) (монотонность) $X \leqslant Y$ п.н. $\implies \mathbb{E}(X|\boldsymbol{\beta}) \leqslant \mathbb{E}(Y|\boldsymbol{\beta})$,
	
	(iii) (аналог формулы полной вероятности) $\mathbb{E}(\mathbb{E}(X|\boldsymbol{\beta})) = \mathbb{E}X$,
	
	(iv) (независимость) если случайная величина $X$ не зависит от разбиения $\boldsymbol{\beta}$, т.е.	случайные величины $X$ и $I_{B_k}$ независимы для каждого $k$, то $\mathbb{E}(X|\boldsymbol{\beta}) = \mathbb{E}X$.
	
	(v) для всякой случайной величины $Z = \sum_{k=1}^n	c_kI_{B_k}$	выполнено $\mathbb{E}(ZX|\boldsymbol{\beta}) = Z\mathbb{E}(X|\boldsymbol{\beta})$.
\end{theorem}
\begin{proof}
	Доказательство. Свойства (i) и (ii) следуют из того, что они верны для $\mathbb{E}(X|B_k)$ для каждого $k$ (т.к. они верны для математического ожидания относительно произвольной вероятностной меры). 
	
	Свойство (iii) проверяется непосредственной подстановкой в определение: $\mathbb{E}(\mathbb{E}(X|\boldsymbol{\beta}))= \mathbb{E}\left(\sum_{k=1}^nI_{B_k}\dfrac{\mathbb{E}(XI_{B_k})}{P(B_k)}\right)=\sum_{k=1}^n\mathbb{E}(XI_{B_k})=\mathbb{E}X$.
	
	Обоснуем пункт (iv). Так как $X$ и $I_{B_k}$ независимы, то $\mathbb{E}(X|B_k) = \dfrac{\mathbb{E}(XI_{B_k})}{P(B_k)}=\dfrac{\mathbb{E}X\mathbb{E}I_{B_k}}{P(B_k)}=\mathbb{E}X$.
	
	Следовательно, $\mathbb{E}(X|\boldsymbol{\beta}) = \sum_{k=1}^n I_{B_k}\mathbb{E}(X|B_k) = \sum_{k=1}^n I_{B_k}\mathbb{E}X = \mathbb{E}X$.
	
	Для обоснования (v) достаточно заметить, что $\mathbb{E}(XZ|B_k) = \dfrac{\mathbb{E}(XZI_{B_k})}{P(B_k)} = c_k \dfrac{\mathbb{E}(XI_{B_k})}{P(B_k)} = c_k\mathbb{E}(X|B_k)$.
	
	ч.т.д.
\end{proof}
\begin{theorem}
	В случае, когда мы рассматриваем условное ожидание относительно случайной величины, свойства следует формулировать так:
	
	(i) (линейность) $\mathbb{E}(\alpha X + \beta Y |Z) = \alpha\mathbb{E}(X|Z) + \beta\mathbb{E}(Y | Z)$,
	
	(ii) (монотонность) $X \leqslant Y$ п.н. $\implies \mathbb{E}(X|Z) \leqslant \mathbb{E}(Y|Z)$,
	
	(iii) (аналог формулы полной вероятности) $\mathbb{E}(\mathbb{E}(X|Y)) = \mathbb{E}X$,
	
	(iv) (независимость) если случайные величины $X$ и $Y$ независимы, то $\mathbb{E}(X|Y) = \mathbb{E}X$.
	
	(v) для всякой случайной величины $Z = g(Y)$ выполнено $\mathbb{E}(ZX|Y ) = Z\mathbb{E}(X|Y )$.
\end{theorem}

\subsubsection{Эквивалентное определение условного математического ожидания и геометрическая интерпретация.}

Для условного математического ожидания выполнено $\mathbb{E}(g(Y)X) = \mathbb{E}(g(Y)\mathbb{E}(X|Y))$ для произвольной функции $g$. Кроме того, если для какой-то случайной величины вида $Z = f(Y)$ выполнено $\mathbb{E}(g(Y)X) = \mathbb{E}(g(Y)Z)$ для произвольной функции $g$, то $Z = \mathbb{E}(X|Y)$ п.н.

\begin{proof} По уже доказанному $\mathbb{E}(g(Y)\mathbb{E}(X|Y))= \mathbb{E}(\mathbb{E}(g(Y)X|Y)))=\mathbb{E}(g(Y)X)$. Наоборот, если $Z = f(Y)$ и обладает указанным свойством, то $\mathbb{E}(g(Y)\mathbb{E}(X|Y))=\mathbb{E}(g(Y)Z)$ для произвольной $g$. Т.к. $\mathbb{E}(X|Y)$ также имеет вид $h(Y)$, то, взяв $g = f - h$, получаем $\mathbb{E}|\mathbb{E}(X|Y)-Z|^2 = 0$, что даёт равенство $Z = \mathbb{E}(X|Y)$ почти наверное.
\end{proof}

\begin{proposal}
	Условное математическое ожидание $\mathbb{E}(X|Y)$ среди всех случайных	величин вида $g(Y)$ является лучшим среднеквадратическим приближением для $X$, т.е. $\underset{Z:Z=g(Y )}{min}	\mathbb{E}|X-Z|^2 = \mathbb{E}|X-\mathbb{E}(X|Y)|^2$.
\end{proposal}

\begin{proof}
	Пусть $Z = g(Y)$. Так как по предыдущей лемме $\mathbb{E}[(X - \mathbb{E}(X|Y))(\mathbb{E}(X|Y) - Z)] = 0$, то $\mathbb{E}|X - Z|^2 = \mathbb{E}|(X-\mathbb{E}(X|Y)) + (\mathbb{E}(X|Y)-Z)|^2 = \mathbb{E}|X-\mathbb{E}(X|Y)|^2 + \mathbb{E}|\mathbb{E}(X|Y)-Z|^2 \geqslant \mathbb{E}|X - \mathbb{E}(X|Y)|^2$.
	
	ч.т.д.
\end{proof}

Таким образом, с геометрической точки зрения условное математическое ожидание является проекцией X на пространство случайных величин вида $g(Y)$ и полностью характеризуется тем свойством, что вектор $X - \mathbb{E}(X|Y)$ ортогонален указанному пространству, что записывается c помощью равенства $\mathbb{E}(Xg(Y)) = \mathbb{E}(\mathbb{E}(X|Y)g(Y))$ для произвольной случайной величины $g(Y)$.
